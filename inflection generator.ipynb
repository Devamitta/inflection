{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert ods to csv\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from aksharamukha import transliterate\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_excel('/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection list generator/declensions & conjugations.xlsx', sheet_name=\"index\", dtype=str)\n",
    "index_df.fillna(\"\", inplace=True)\n",
    "# index_df[\"inflection name\"] = index_df[\"inflection name\"].str.replace(\" \", \"_\") #only needed if using as variable\n",
    "index_df_length = len(index_df)\n",
    "\n",
    "index_df.columns\n",
    "index_dict = dict(zip(index_df.iloc[:, 0], index_df.iloc[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate df's of each inflection pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~\" * 40)\n",
    "print(\"inflection generator.ipynb\")\n",
    "print(\"~\" * 40)\n",
    "\n",
    "inflection_df = pd.read_excel('/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection list generator/declensions & conjugations.xlsx', sheet_name=\"declensions\", dtype=str)\n",
    "\n",
    "inflection_df = inflection_df.shift(periods=2)\n",
    "\n",
    "inflection_df.columns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"AC\", \"AD\", \"AE\", \"AF\", \"AG\", \"AH\", \"AI\", \"AJ\", \"AK\", \"AL\", \"AM\", \"AN\", \"AO\", \"AP\", \"AQ\", \"AR\", \"AS\", \"AT\", \"AU\", \"AV\", \"AW\", \"AX\", \"AY\", \"AZ\", \"BA\", \"BB\", \"BC\", \"BD\", \"BE\", \"BF\", \"BG\", \"BH\", \"BI\", \"BJ\", \"BK\", \"BL\", \"BM\", \"BN\", \"BO\", \"BP\", \"BQ\", \"BR\", \"BS\", \"BT\", \"BU\", \"BV\", \"BW\", \"BX\", \"BY\", \"BZ\", \"CA\", \"CB\", \"CC\", \"CD\", \"CE\", \"CF\", \"CG\", \"CH\", \"CI\", \"CJ\", \"CK\", \"CL\", \"CM\", \"CN\", \"CO\", \"CP\", \"CQ\", \"CR\", \"CS\", \"CT\", \"CU\", \"CV\", \"CW\", \"CX\", \"CY\", \"CZ\", \"DA\", \"DB\", \"DC\", \"DD\", \"DE\", \"DF\", \"DG\", \"DH\", \"DI\", \"DJ\", \"DK\"]\n",
    "inflection_df.fillna(\"\", inplace=True)\n",
    "\n",
    "pattern_changed = []\n",
    "\n",
    "for row in range(index_df_length): #index_df_length\n",
    "\tinflection_name = index_df.iloc[row,0]\n",
    "\tcell_range = index_df.iloc[row,1]\n",
    "\tlike = index_df.iloc[row,2]\n",
    "\tirreg = index_df.iloc[row,3]\n",
    "\n",
    "\tcol_range_1 = re.sub(\"(.+?)\\d*\\:.+\", \"\\\\1\", cell_range)\n",
    "\tcol_range_2 = re.sub(\".+\\:(.[A-Z]*)\\d*\", \"\\\\1\", cell_range)\n",
    "\trow_range_1 = int(re.sub(\".+?(\\d{1,3}):.+\", \"\\\\1\", cell_range))\n",
    "\trow_range_2 = int(re.sub(\".+:.+?(\\d{1,3})\", \"\\\\1\", cell_range))\n",
    "\n",
    "\tinflection_df_filtered = inflection_df.loc[row_range_1:row_range_2, col_range_1:col_range_2]\n",
    "\tinflection_df_filtered.Name =  f\"{inflection_name}\"\n",
    "\n",
    "\tinflection_df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\tinflection_df_filtered.iloc[0,0] = \"\"\n",
    "\n",
    "\t# replace header\n",
    "\n",
    "\tnew_header = inflection_df_filtered.iloc[0] #grab the first row for the header\n",
    "\tinflection_df_filtered = inflection_df_filtered[1:] #take the data less the header row\n",
    "\tinflection_df_filtered.columns = new_header #set the header row as the df header\n",
    "\n",
    "\t# replace index\n",
    "\n",
    "\tinflection_df_filtered.index = inflection_df_filtered.iloc[0:,0]\n",
    "\tinflection_df_filtered = inflection_df_filtered.iloc[:, 1:]\n",
    "\n",
    "\t# remove unmaed column headers\n",
    "\n",
    "\tinflection_df_filtered = inflection_df_filtered.rename(columns=lambda x: re.sub('Unnamed.*','',x))\n",
    "\n",
    "\t# test\n",
    "\n",
    "\ttry:\n",
    "\t\told = pd.read_csv(f\"output/patterns/{inflection_name}.csv\", sep=\"\\t\", index_col=0, na_filter=False) #, header=0\n",
    "\t\told.fillna(\"\", inplace=True)\n",
    "\t\told = old.rename(columns=lambda x: re.sub('Unnamed.*','',x))\n",
    "\texcept:\n",
    "\t\tprint(f\"{inflection_name} - doesn't exist - added\")\n",
    "\t\tpattern_changed.append(inflection_name)\n",
    "\t\tinflection_df_filtered.to_csv(f\"output/patterns/{inflection_name}.csv\", sep=\"\\t\")\n",
    "\n",
    "\tif inflection_df_filtered.equals(old):\n",
    "\t\tcontinue\n",
    "\telif inflection_name in pattern_changed:\n",
    "\t\tcontinue\n",
    "\telif not inflection_df_filtered.equals(old):\n",
    "\t\tprint(f\"{inflection_name} - different - updated\")\n",
    "\t\tinflection_df_filtered.to_csv(f\"output/patterns/{inflection_name}.csv\", sep=\"\\t\")\n",
    "\t\tpattern_changed.append(inflection_name)\n",
    "\n",
    "if pattern_changed == []:\n",
    "\tprint(\"all patterns identical\")\n",
    "if pattern_changed != []:\n",
    "\tprint(\"~\" * 40)\n",
    "\tprint(f\"the following patterns have changes and will be generated\\n{pattern_changed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dpd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpd_df = pd.read_csv(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd-full.csv\", sep=\"\\t\", dtype=str)\n",
    "dpd_df.fillna(\"\", inplace=True) \n",
    "dpd_df_length = len(dpd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test for missing stem & pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty stem\n",
    "\n",
    "error = False\n",
    "\n",
    "for row in range(dpd_df_length):\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\t\n",
    "\tif stem == \"\":\n",
    "\t\tprint(f\"stem error: {headword} has no stem!\")\n",
    "\t\terror = True\n",
    "\tif stem != \"-\" and pattern == \"\":\n",
    "\t\tprint(f\"pattern error: {headword} has no pattern!\")\n",
    "\t\terror = True\n",
    "\n",
    "if error == True:\n",
    "\tprint(\"~\" * 40)\n",
    "\tinput(\"there are stem & pattern errors, please fix them before continuiing\")\n",
    "else:\n",
    "\tprint(\"~\" * 40)\n",
    "\tprint(\"no stem & pattern errors found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test for wrong patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~\" * 40)\n",
    "print(\"testing for wrong patterns\")\n",
    "\n",
    "index_patterns = index_df[\"inflection name\"].values.tolist()\n",
    "\n",
    "error = False\n",
    "\n",
    "fixme = \"\"\n",
    "\n",
    "for row in range(dpd_df_length):\n",
    "\theadword =  dpd_df.loc[row, \"Pāli1\"]\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\n",
    "\tif stem == \"-\":\n",
    "\t\tpass\n",
    "\t\t# print(f\"pass. {headword} stem \")\n",
    "\telif stem == \"!\":\n",
    "\t\tpass\n",
    "\t\t# print(f\"pass {headword} stem !\")\n",
    "\telif pattern in index_patterns:\n",
    "\t\tpass\n",
    "\t\t# print(f\"pass {headword} {pattern} exists\")\n",
    "\telif pattern not in index_patterns:\n",
    "\t\tprint(\"~\" * 40)\n",
    "\t\tprint(f\"oops! {headword}. {pattern}\")\n",
    "\t\terror = True\n",
    "\telse:\n",
    "\t\tpass\n",
    "\n",
    "if error == True:\n",
    "\tprint(\"~\" * 40)\n",
    "\tinput(\"wrong patterns - fix 'em!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test for differences in stem and pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed = []\n",
    "\n",
    "print(\"~\" * 40)\n",
    "print(\"testing for changes in stem and pattern\")\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tnew = f\"{headword} {stem} {pattern}\"\n",
    "\n",
    "\ttry:\n",
    "\t\tpickle_file = open(f\"output/pickle test/{headword}\",\"rb\")\n",
    "\t\told = pickle.load(pickle_file)\n",
    "\t\tpickle_file.close()\n",
    "\texcept:\n",
    "\t\tprint(f\"{headword} - doesn't exist - added\")\n",
    "\t\tchanged.append(headword)\n",
    "\t\tpickle_file = open(f\"output/pickle test/{headword}\",\"wb\")\n",
    "\t\tpickle.dump(new,pickle_file)\n",
    "\t\tpickle_file.close()\n",
    "\t\tcontinue\n",
    "\n",
    "\tif old == new:\n",
    "\t\tcontinue\n",
    "\telif old in changed:\n",
    "\t\tcontinue\n",
    "\telif old != new:\n",
    "\t\tprint(f\"{headword} {stem} {pattern} - not identical\")\n",
    "\t\tchanged.append(headword)\n",
    "\t\tpickle_file = open(f\"output/pickle test/{headword}\",\"wb\")\n",
    "\t\tpickle.dump(new,pickle_file)\n",
    "\t\tpickle_file.close()\n",
    "\n",
    "print(\"~\"*40)\n",
    "if changed == []:\n",
    "\tprint(\"no headwords stems or patterns changed\")\n",
    "if changed != []:\n",
    "\tprint(f\"the following patterns have changes and will be generated:\\n{changed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test if inflections exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_not_exist = []\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\t\n",
    "\ttry:\n",
    "\t\twith open(f\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection list generator/output/synonyms/{headword}\", \"rb\") as syn_file:\n",
    "\t\t\tpass\n",
    "\t\n",
    "\texcept:\n",
    "\t\tprint(f\"synoym file for - {headword} - doesn't exist\")\n",
    "\t\tsynonyms_not_exist.append(headword)\n",
    "\n",
    "print(\"~\"*40)\n",
    "\n",
    "if synonyms_not_exist == []:\n",
    "\tprint(\"no missing synonym files\")\n",
    "if synonyms_not_exist != []:\n",
    "\tprint(f\"the following synonym files are missing and will be generated:\\n{synonyms_not_exist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all html inflection tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~\" * 40)\n",
    "print(\"generating inflection tables\")\n",
    "print(\"~\" * 40)\n",
    "\n",
    "indeclinables = [\"abbrev\", \"abs\", \"ger\", \"ind\", \"inf\", \"prefix\"]\n",
    "conjugations = [\"aor\", \"cond\", \"fut\", \"imp\", \"imperf\", \"opt\", \"perf\", \"pr\"]\n",
    "declensions = [\"adj\", \"card\", \"cs\", \"fem\", \"letter\", \"masc\", \"nt\", \"ordin\", \"pp\", \"pron\", \"prp\", \"ptp\", \"root\", \"suffix\", \"ve\"]\n",
    "\n",
    "row = 0\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tif stem == \"*\":\n",
    "\t\tstem = \"\"\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tpos = dpd_df.loc[row, \"POS\"]\n",
    "\tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "\tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\n",
    "\tif headword in changed or pattern in pattern_changed or headword in synonyms_not_exist:\n",
    "\t\tprint(f\"{row}/{dpd_df_length}\\t{headword}\")\n",
    "\n",
    "\t\twith open(f\"output/html/{headword}.html\", \"w\") as html_table:\n",
    "\t\t\t\t\n",
    "\t\t\tif stem == \"-\":\n",
    "\t\t\t\thtml_table.write(f\"<p><b>{headword_clean}</b> is indeclinable\")\n",
    "\n",
    "\t\t\telif stem == \"!\":\n",
    "\t\t\t\thtml_table.write(f\"<p>click on <b>{pattern}</b> for inflection table\")\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", index_col=0)\n",
    "\t\t\t\tdf.fillna(\"\", inplace=True, axis=0)\n",
    "\t\t\t\t\n",
    "\t\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\t\tfor rows in range(0, df_rows): \n",
    "\t\t\t\t\tfor columns in range(0, df_columns, 2): #1 to 0\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\thtml_cell = df.iloc[rows, columns]\n",
    "\t\t\t\t\t\tsyn_cell = df.iloc[rows, columns]\t\n",
    "\n",
    "\t\t\t\t\t\tif html_cell == \"sg\" or html_cell == \"pl\":\n",
    "\t\t\t\t\t\t\tpass\n",
    "\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\thtml_cell = re.sub(r\"(.+)\", f\"<b>\\\\1</b>\", html_cell) # add bold\n",
    "\t\t\t\t\t\t\thtml_cell = re.sub(r\"(.+)\", f\"{stem}\\\\1\", html_cell) # add stem\n",
    "\t\t\t\t\t\t\thtml_cell = re.sub(r\"\\n\", \"<br>\", html_cell) # add line breaks\n",
    "\t\t\t\t\t\t\tdf.iloc[rows, columns] = html_cell\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tsyn_cell = re.sub(r\"(.+)\", f\"{stem}\\\\1\", syn_cell)\n",
    "\t\t\t\t\t\t\tsearch_string = re.compile(\"\\n\", re.M)\n",
    "\t\t\t\t\t\t\treplace_string = \" \"\n",
    "\t\t\t\t\t\t\tmatches = re.sub(search_string, replace_string, syn_cell)\n",
    "\t\t\t\t\t\t\t# synonyms += matches + \" \"\n",
    "\t\t\t\t\n",
    "\t\t\t\tcolumn_list = []\n",
    "\t\t\t\tfor i in range(1, df_columns, 2):\n",
    "\t\t\t\t\tcolumn_list.append(i)\n",
    "\n",
    "\t\t\t\tdf.drop(df.columns[column_list], axis=1, inplace=True)\n",
    "\t\t\t\ttable = df.to_html(escape=False)\n",
    "\t\t\t\ttable = re.sub(\"Unnamed.+\", \"\", table)\n",
    "\t\t\t\ttable = re.sub(\"NaN\", \"\", table)\n",
    "\n",
    "\t\t\t\t# write header info\n",
    "\n",
    "\t\t\t\tif index_dict[pattern] != \"\":\n",
    "\t\t\t\t\tif pos in declensions:\n",
    "\t\t\t\t\t\theading = (f\"\"\"<p><b>{headword_clean}</b> is <b>{pattern}</b> declension like <b>{index_dict[pattern]}</b></p>\"\"\")\n",
    "\t\t\t\t\tif pos in conjugations:\n",
    "\t\t\t\t\t\theading = (f\"\"\"<p><b>{headword_clean}</b> is <b>{pattern}</b> conjugation like <b>{index_dict[pattern]}</b></p>\"\"\")\n",
    "\n",
    "\t\t\t\tif index_dict[pattern] == \"\":\n",
    "\t\t\t\t\tif pos in declensions:\n",
    "\t\t\t\t\t\theading = (f\"\"\"<p><b>{headword_clean}</b> is <b>{pattern}</b> irregular declension</p>\"\"\")\n",
    "\t\t\t\t\tif pos in conjugations:\n",
    "\t\t\t\t\t\theading = (f\"\"\"<p><b>{headword_clean}</b> is <b>{pattern}</b> irregular conjugation</p>\"\"\")\n",
    "\t\t\t\t\n",
    "\t\t\t\thtml = heading + table \n",
    "\t\t\t\thtml_table.write(html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~\" * 40)\n",
    "print(\"generating synonyns\")\n",
    "print(\"~\" * 40)\n",
    "\n",
    "new_synonyms_dict = {}\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tif stem == \"*\":\n",
    "\t\tstem = \"\"\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tpos = dpd_df.loc[row, \"POS\"]\n",
    "\tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "\tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\tvariant = dpd_df.loc[row, \"Variant – same constr or diff reading\"]\n",
    "\n",
    "\tsynonyms = \"\"\n",
    "\n",
    "\tif headword in changed or pattern in pattern_changed or headword in synonyms_not_exist:\n",
    "\t# if 1== 1:\n",
    "\t\tprint(f\"{row} {headword}\")\n",
    "\n",
    "\t\tif stem == \"-\":\n",
    "\t\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\t\telif stem == \"!\":\n",
    "\t\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\t\t\tvariant = re.sub(\",\", \" \", variant)\n",
    "\t\t\tsynonyms += variant + \" \"\n",
    "\t\t\n",
    "\t\t\ttry:\n",
    "\t\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", header=None)\n",
    "\t\t\t\tdf.fillna(\"\", inplace=True)\n",
    "\t\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\t\tfor rows in range(1, df_rows):\n",
    "\t\t\t\t\tfor columns in range(1, df_columns, 2):\n",
    "\t\t\t\t\t\tline = df.iloc[rows, columns]\n",
    "\t\t\t\t\t\tline = re.sub(r\"(.+)\", f\"{stem}\\\\1\", line)\n",
    "\t\t\t\t\t\tsearch_string = re.compile(\"\\n\", re.M)\n",
    "\t\t\t\t\t\treplace_string = \" \"\n",
    "\t\t\t\t\t\tmatches = re.sub(search_string, replace_string, line)\n",
    "\n",
    "\t\t\t\t\t\tsynonyms += matches + \" \"\n",
    "\n",
    "\t\t\texcept:\n",
    "\t\t\t\twith open(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/errorlogs/inflection generator errorlog.txt\", \"a\") as error_log:\n",
    "\t\t\t\t\terror_log.write(f\"error on: {headword}\\n\")\n",
    "\t\t\n",
    "\t\tthis_word_synonyms = {headword : synonyms}\n",
    "\t\tnew_synonyms_dict.update(this_word_synonyms)\n",
    "\n",
    "if new_synonyms_dict != {}:\n",
    "\tnew_synonyms_df = pd.DataFrame.from_dict(new_synonyms_dict, orient='index')\n",
    "\tnew_synonyms_df.to_csv(\"output/new synonyms.csv\", sep=\"\\t\", header=False)\n",
    "\n",
    "else:\n",
    "\tprint(\"no new synonyms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcribe new synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_synonyms_dict != {}:\n",
    "  print(\"~\" * 40)\n",
    "\n",
    "  new_synonyms = open(\"output/new synonyms.csv\", \"r\")\n",
    "  new_synonyms_read = new_synonyms.read()\n",
    "  new_synonyms.close()\n",
    "\n",
    "  new_synonyms_translit = open(\"output/new synonyms translt.csv\", \"w\")\n",
    "\n",
    "  print(\"converting synonyms to sinhala\")\n",
    "  sinhala = transliterate.process(\"IAST\",\"Sinhala\", new_synonyms_read, post_options =['SinhalaPali', 'SinhalaConjuncts'])\n",
    "  \n",
    "  print(\"converting synonyms to devanagari\")\n",
    "  devanagari = transliterate.process(\"IAST\",\"Devanagari\",new_synonyms_read, post_options = ['DevanagariAnusvara'])\n",
    "\n",
    "  roman = new_synonyms_read.split(\"\\n\")[:-1]\n",
    "  sinhala = sinhala.split(\"\\n\")\n",
    "  devanagari = devanagari.split(\"\\n\")\n",
    "\n",
    "  for i in zip(roman, sinhala, devanagari):\t\n",
    "    new_synonyms_translit.write(i[0]+i[1].split(\"\\t\")[1]+i[2].split(\"\\t\")[1]+\"\\n\")\n",
    "\n",
    "  new_synonyms_translit.close()\n",
    "\n",
    "else:\n",
    "\tprint(\"no new synonyms to transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = pd.DataFrame()\n",
    "\n",
    "if new_synonyms_dict != {}:\n",
    "    all_synonyms_translit = pd.read_csv(\"output/all synonyms translt.csv\", header=None, sep=\"\\t\")\n",
    "\n",
    "    new_synonyms_translit = pd.read_csv(\"output/new synonyms translt.csv\", header=None, sep=\"\\t\")\n",
    "\n",
    "    diff = pd.merge(all_synonyms_translit, new_synonyms_translit, on=[0], how='outer', indicator='exists')\n",
    "    diff.to_csv(\"output/diff.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "    # copy changes\n",
    "\n",
    "    test1 = diff[\"exists\"] == \"both\"\n",
    "    test2 = diff[\"1_y\"] != \"\"\n",
    "    filter = test1 & test2\n",
    "    diff.loc[filter, \"1_x\"] = diff.loc[filter, \"1_y\"]\n",
    "\n",
    "    # add new\n",
    "\n",
    "    test1 = diff[\"exists\"] == \"right_only\"\n",
    "    test2 = diff[\"1_y\"] != \"\"\n",
    "    filter = test1 & test2\n",
    "    diff.loc[filter, \"1_x\"] = diff.loc[filter, \"1_y\"]\n",
    "\n",
    "    # !!! how to delete non existent\n",
    "\n",
    "    # drop columns and write to csv\n",
    "\n",
    "    diff.drop(columns=[\"1_y\", \"exists\"], inplace=True)\n",
    "\n",
    "    diff.to_csv(\"output/all synonyms translt.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "else:\n",
    "    print(\"all synonyms translt.csv unchanged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~\" * 40)\n",
    "print(\"exporting synonyms to pickle\")\n",
    "\n",
    "\n",
    "all_synonyms = diff\n",
    "\n",
    "length = len(all_synonyms)\n",
    "\n",
    "for row in range(length):\n",
    "\n",
    "\theadword = all_synonyms.iloc[row, 0]\n",
    "\tsynonyms = all_synonyms.iloc[row, 1]\n",
    "\n",
    "\t# !!! how to delete headword when no longer exists\t??? \n",
    "\t\n",
    "\tif headword in new_synonyms_dict.keys():\n",
    "\t\tprint(headword)\n",
    "\n",
    "\t\tsynonyms_list = synonyms.split()\n",
    "\n",
    "\t\t# add ṁ version\n",
    "\n",
    "\t\tfor word in synonyms_list:\n",
    "\t\t\tif 'ṃ' in word:\n",
    "\t\t\t\twordṁ = re.sub(\"ṃ\", \"ṁ\", word) \n",
    "\t\t\t\tsynonyms_list.append(wordṁ)\n",
    "\n",
    "\t\tsynonyms_list = list(dict.fromkeys(synonyms_list))\n",
    "\n",
    "\t\twith open(f\"output/synonyms/{headword}\", \"wb\") as text_file:\n",
    "\t\t\tpickle.dump(synonyms_list, text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all changes since last run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle_file = open(\"output/all changes since last run\", \"rb\")\n",
    "# # old_changes = pickle.load(pickle_file)\n",
    "# # pickle_file.close\n",
    "# # print(old_changes)\n",
    "\n",
    "# # all_changes = old_changes\n",
    "# all_changes = []\n",
    "# all_changes += new_synonyms_dict.keys()\n",
    "# all_changes += changed\n",
    "\n",
    "# pickle_file = open(\"output/all changes since last run\", \"ab+\")\n",
    "# pickle.dump(all_changes, pickle_file)\n",
    "# pickle_file.close\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
