{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert ods to csv\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from aksharamukha import transliterate\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in inflections table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflection_df = pd.read_excel('/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection-generator/declensions & conjugations.xlsx', sheet_name=\"declensions\", dtype=str)\n",
    "\n",
    "inflection_df = inflection_df.shift(periods=2)\n",
    "\n",
    "inflection_df.columns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"AC\", \"AD\", \"AE\", \"AF\", \"AG\", \"AH\", \"AI\", \"AJ\", \"AK\", \"AL\", \"AM\", \"AN\", \"AO\", \"AP\", \"AQ\", \"AR\", \"AS\", \"AT\", \"AU\", \"AV\", \"AW\", \"AX\", \"AY\", \"AZ\", \"BA\", \"BB\", \"BC\", \"BD\", \"BE\", \"BF\", \"BG\", \"BH\", \"BI\", \"BJ\", \"BK\", \"BL\", \"BM\", \"BN\", \"BO\", \"BP\", \"BQ\", \"BR\", \"BS\", \"BT\", \"BU\", \"BV\", \"BW\", \"BX\", \"BY\", \"BZ\", \"CA\", \"CB\", \"CC\", \"CD\", \"CE\", \"CF\", \"CG\", \"CH\", \"CI\", \"CJ\", \"CK\", \"CL\", \"CM\", \"CN\", \"CO\", \"CP\", \"CQ\", \"CR\", \"CS\", \"CT\", \"CU\", \"CV\", \"CW\", \"CX\", \"CY\", \"CZ\", \"DA\", \"DB\", \"DC\", \"DD\", \"DE\", \"DF\", \"DG\", \"DH\", \"DI\", \"DJ\", \"DK\"]\n",
    "inflection_df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_excel('/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection-generator/declensions & conjugations.xlsx', sheet_name=\"index\", dtype=str)\n",
    "index_df.fillna(\"\", inplace=True)\n",
    "# index_df[\"inflection name\"] = index_df[\"inflection name\"].str.replace(\" \", \"_\") #only needed if using as variable\n",
    "index_df_length = len(index_df)\n",
    "\n",
    "index_df.columns\n",
    "index_dict = dict(zip(index_df.iloc[:, 0], index_df.iloc[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate df's of each inflection pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for row in range(index_df_length):\n",
    "\tinflection_name = index_df.iloc[row,0]\n",
    "\tcell_range = index_df.iloc[row,1]\n",
    "\tlike = index_df.iloc[row,2]\n",
    "\tirreg = index_df.iloc[row,3]\n",
    "\n",
    "\tcol_range_1 = re.sub(\"(.+?)\\d*\\:.+\", \"\\\\1\", cell_range)\n",
    "\tcol_range_2 = re.sub(\".+\\:(.[A-Z]*)\\d*\", \"\\\\1\", cell_range)\n",
    "\trow_range_1 = int(re.sub(\".+?(\\d{1,3}):.+\", \"\\\\1\", cell_range))\n",
    "\trow_range_2 = int(re.sub(\".+:.+?(\\d{1,3})\", \"\\\\1\", cell_range))\n",
    "\n",
    "\t# print (f\"{inflection_name} || {cell_range} || {col_range_1}:{col_range_2} || {row_range_1}:{row_range_2}\")\n",
    "\n",
    "\tinflection_df_filtered = inflection_df.loc[row_range_1:row_range_2, col_range_1:col_range_2]\n",
    "\tinflection_df_filtered.Name =  f\"{inflection_name}\" #help! change the name to \"inflection name\" \n",
    "\n",
    "\tinflection_df_filtered.to_csv(f\"output/patterns/{inflection_name}.csv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all inflection tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 akakkasa\n",
      "2000 anatisāra\n",
      "4000 appāṭihīrakata\n",
      "6000 asaṃvijjamāna\n",
      "8000 idāneva\n",
      "10000 ummādana\n",
      "12000 kampetvā\n",
      "14000 khalagga\n",
      "16000 ciraṭṭhitika\n",
      "18000 tabbiparīta\n",
      "20000 dutiyaṃ\n",
      "22000 niggaheti 1\n",
      "24000 pajja 3\n",
      "26000 payoga 3\n",
      "28000 pānaka\n",
      "30000 byañjanakusala\n",
      "32000 mahāsamuddapiṭṭha\n",
      "34000 rukkhattaca\n",
      "36000 vikkiṇi\n",
      "38000 vuṭṭhāsi\n",
      "40000 sannivesa 2\n",
      "42000 saṃyūhati\n",
      "44000 selamaya\n"
     ]
    }
   ],
   "source": [
    "dpd_df = pd.read_csv(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd-full.csv\", sep=\"\\t\", dtype=str)\n",
    "dpd_df.fillna(\"\", inplace=True) \n",
    "dpd_df_length = len(dpd_df)\n",
    "\n",
    "indeclinables = [\"abbrev\", \"abs\", \"ger\", \"ind\", \"inf\", \"prefix\"]\n",
    "conjugations = [\"aor\", \"cond\", \"fut\", \"imp\", \"imperf\", \"opt\", \"perf\", \"pr\"]\n",
    "declensions = [\"adj\", \"card\", \"cs\", \"fem\", \"letter\", \"masc\", \"nt\", \"ordin\", \"pp\", \"pron\", \"prp\", \"ptp\", \"root\", \"suffix\", \"ve\"]\n",
    "\n",
    "row = 0\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tif stem == \"*\":\n",
    "\t\tstem = \"\"\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tpos = dpd_df.loc[row, \"POS\"]\n",
    "\tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "\tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\n",
    "\tif row % 5000 == 0:\n",
    "\t\tprint(f\"{row} {headword}\")\n",
    "\t\n",
    "\twith open(f\"output/html/{headword}.html\", \"w\") as html_table:\n",
    "\n",
    "\t\tif stem == \"-\":\n",
    "\t\t\thtml_table.write(f\"<p><b>{headword_clean}</b> is indeclinable\")\n",
    "\n",
    "\t\telif stem == \"!\":\n",
    "\t\t\thtml_table.write(f\"<p>click on <b>{pattern}</b> for inflection table\")\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", header=None)\n",
    "\t\t\tdf.fillna(\"\", inplace=True)\n",
    "\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\tfor rows in range(1, df_rows):\n",
    "\t\t\t\tfor columns in range(1, df_columns, 2):\n",
    "\t\t\t\t\tcell = df.iloc[rows, columns]\n",
    "\n",
    "\t\t\t\t\tif cell == \"sg\" or cell == \"pl\":\n",
    "\t\t\t\t\t\tpass\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tcell = re.sub(r\"(.+)\", f\"<b>\\\\1</b>\", cell) # add bold\n",
    "\t\t\t\t\t\tcell = re.sub(r\"(.+)\", f\"{stem}\\\\1\", cell) # add stem\n",
    "\t\t\t\t\t\tcell = re.sub(r\"\\n\", \"<br>\", cell) # add line breaks\n",
    "\t\t\t\t\t\tdf.iloc[rows, columns] = cell\n",
    "\t\t\t\n",
    "\t\t\tfor columns in range(2, df_columns, 2):\t# drop extra rows\n",
    "\t\t\t\tdf.drop([columns], axis=1, inplace=True) \n",
    "\t\t\t\n",
    "\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\thtml_file = open (f\"output/html/{headword}.html\", \"w\")\n",
    "\t\t\t\n",
    "\t\t\t# write header info\n",
    "\n",
    "\t\t\tif index_dict[pattern] != \"\":\n",
    "\t\t\t\tif pos in declensions:\n",
    "\t\t\t\t\thtml_file.write(f\"\"\"<p><b>{headword_clean}</b> is <b>\"{pattern}\"</b> declined like <b>{index_dict[pattern]}</b></p>\"\"\")\n",
    "\t\t\t\tif pos in conjugations:\n",
    "\t\t\t\t\thtml_file.write(f\"\"\"<p><b>{headword_clean}</b> is <b>\"{pattern}\"</b> conjugated like <b>{index_dict[pattern]}</b></p>\"\"\")\n",
    "\n",
    "\t\t\tif index_dict[pattern] == \"\":\n",
    "\t\t\t\tif pos in declensions:\n",
    "\t\t\t\t\thtml_file.write(f\"\"\"<p><b>{headword_clean}</b> is <b>\"{pattern}\"</b> irregular declension</p>\"\"\")\n",
    "\t\t\t\tif pos in conjugations:\n",
    "\t\t\t\t\thtml_file.write(f\"\"\"<p><b>{headword_clean}</b> is <b>\"{pattern}\"</b> irregular conjugation</p>\"\"\")\n",
    "\n",
    "\t\t\tfor rows in range(df_rows):\n",
    "\t\t\t\tfor columns in range(df_columns):\n",
    "\t\t\t\t\tcell = df.iloc[rows, columns]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif rows == 0 and columns == 0:\n",
    "\t\t\t\t\t\tcell = \"\"\"<table class = \"table2\"><tr><th></th>\"\"\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows == 0 and columns > 0 and columns < df_columns-1:\n",
    "\t\t\t\t\t\tcell = \"<th>\" + cell + \"</th>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows > 0 and rows <= df_rows-1 and columns == 0 :\n",
    "\t\t\t\t\t\tcell = \"<tr><th>\" + cell + \"</th>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows > 0 and rows <= df_rows-1 and columns > 0  and columns < df_columns-1:\n",
    "\t\t\t\t\t\tcell = \"<td>\" + cell + \"</td>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows == df_rows-1 and columns == df_columns-1:\n",
    "\t\t\t\t\t\tcell = \"<td>\" + cell + \"</td></table>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\thtml_file.close()\n",
    "\n",
    "\n",
    "\t\t\t# for columns in range(df_columns): # add table html\n",
    "\t\t\t# \ttry:\n",
    "\t\t\t# \t\tif columns == 0:\n",
    "\t\t\t# \t\t\tdf.iloc[0, columns] = \"\"\"<table class = \"table2\"><tr><th>\"\"\" + df.iloc[0, columns] + \"</th>\"\n",
    "\t\t\t# \t\t\tdf.iloc[1:, columns] =  \"<tr><th>\" + df.loc[1:, columns] + \"</th>\"\n",
    "\t\t\t# \t\tif columns > 0:\n",
    "\t\t\t# \t\t\tdf.iloc[0, columns] = \"<th>\" + df.iloc[0, columns] + \"</th>\"\n",
    "\t\t\t# \t\t\tdf.iloc[1:, columns] =  \"<td>\" + df.iloc[1:, columns] + \"</td>\"\n",
    "\t\t\t# \t\tif columns == df_columns:\n",
    "\t\t\t# \t\t\tdf.iloc[df_rows, df_columns] =  df.iloc[df_rows, df_columns] + \"</table>\"\n",
    "\n",
    "\t\t\t# \texcept:\n",
    "\t\t\t# \t\twith open(\"output/table errors.txt\", \"a\") as table_error_log:\n",
    "\t\t\t# \t\t\ttable_error_log.write(f\"\")\n",
    "\t\t\t# \t\t\ttable_error_log.write(f\"{headword=}\\n{columns=}\\n\\n\")\n",
    "\t\n",
    "\t\t\t# df.to_csv(f\"output/html/{headword}.html\",  sep=\" \", index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 akakkasa\n",
      "1000 aṭṭhakappa\n",
      "2000 anatisāra\n",
      "3000 anusari\n",
      "4000 appāṭihīrakata\n",
      "5000 amhākañceso\n",
      "6000 asaṃvijjamāna\n",
      "7000 ābhogasamannāhāra\n",
      "8000 idāneva\n",
      "9000 unnala\n",
      "10000 ummādana\n",
      "11000 odhūta\n",
      "12000 kampetvā\n",
      "13000 kimaṅgaṃ\n",
      "14000 khalagga\n",
      "15000 gulāguṇṭhikajāta\n",
      "16000 ciraṭṭhitika\n",
      "17000 jigucchita\n",
      "18000 tabbiparīta\n",
      "19000 thunanta\n",
      "20000 dutiyaṃ\n",
      "21000 dhūpetvā\n",
      "22000 niggaheti 1\n",
      "23000 nisinnavattika\n",
      "24000 pajja 3\n",
      "25000 paṭṭhapita 2\n",
      "26000 payoga 3\n",
      "27000 parivīmaṃsati\n",
      "28000 pānaka\n",
      "29000 pulava\n",
      "30000 byañjanakusala\n",
      "31000 bhoga 3\n",
      "32000 mahāsamuddapiṭṭha\n",
      "33000 yathāninnaṃ\n",
      "34000 rukkhattaca\n",
      "35000 vaḍḍheti 1\n",
      "36000 vikkiṇi\n",
      "37000 vibhāsā\n",
      "38000 vuṭṭhāsi\n",
      "39000 saṅghāṭipattacīvara\n",
      "40000 sannivesa 2\n",
      "41000 samodhāna\n",
      "42000 saṃyūhati\n",
      "43000 sīlavant\n",
      "44000 selamaya\n"
     ]
    }
   ],
   "source": [
    "dpd_df = pd.read_csv(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd-full.csv\", sep=\"\\t\", dtype=str)\n",
    "dpd_df.fillna(\"\", inplace=True)\n",
    "dpd_df_length = len(dpd_df)\n",
    "\n",
    "all_synonyms = open (\"output/all synonyms.csv\", \"w\")\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tif stem == \"*\":\n",
    "\t\tstem = \"\"\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tpos = dpd_df.loc[row, \"POS\"]\n",
    "\tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "\tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\n",
    "\tsynonyms = \"\"\n",
    "\n",
    "\tif row % 5000 == 0:\n",
    "\t\tprint(f\"{row} {headword}\")\n",
    "\n",
    "\tif stem == \"-\":\n",
    "\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\telif stem == \"!\":\n",
    "\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\telse:\n",
    "\t\ttry:\n",
    "\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", header=None)\n",
    "\t\t\tdf.fillna(\"\", inplace=True)\n",
    "\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\tfor rows in range(1, df_rows):\n",
    "\t\t\t\tfor columns in range(1, df_columns, 2):\n",
    "\t\t\t\t\tline = df.iloc[rows, columns]\n",
    "\t\t\t\t\tif line == \"sg\" or line == \"pl\":\n",
    "\t\t\t\t\t\tpass\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tline = re.sub(r\"(.+)\", f\"{stem}\\\\1\", line)\n",
    "\t\t\t\t\t\tsearch_string = re.compile(\"\\n\", re.M)\n",
    "\t\t\t\t\t\treplace_string = \" \"\n",
    "\t\t\t\t\t\tmatches = re.sub(search_string, replace_string, line)\n",
    "\n",
    "\t\t\t\t\t\tsynonyms += matches + \" \"\n",
    "\t\t\t\t\t\n",
    "\t\texcept:\n",
    "\t\t\twith open(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/errorlogs/inflection generator errorlog.txt\", \"a\") as error_log:\n",
    "\t\t\t\terror_log.write(f\"error on: {headword}\\n\")\n",
    "\t\n",
    "\tall_synonyms.write(f\"{headword}\t{synonyms}\\n\")\n",
    "\n",
    "all_synonyms.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcribe synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synonyms = open(\"output/all synonyms.csv\", \"r\")\n",
    "all_synonyms_read = all_synonyms.read()\n",
    "all_synonyms.close()\n",
    "\n",
    "all_synonyms_translit = open(\"output/all synonyms translt.csv\", \"w\")\n",
    "\n",
    "sinhala = transliterate.process(\"IAST\",\"Sinhala\", all_synonyms_read, post_options =['SinhalaPali', 'SinhalaConjuncts'])\n",
    "devanagari = transliterate.process(\"IAST\",\"Devanagari\",all_synonyms_read, post_options = ['DevanagariAnusvara'])\n",
    "\n",
    "roman = all_synonyms_read.split(\"\\n\")[:-1]\n",
    "sinhala = sinhala.split(\"\\n\")\n",
    "devanagari = devanagari.split(\"\\n\")\n",
    "\n",
    "for i in zip(roman, sinhala, devanagari):\t\n",
    "  all_synonyms_translit.write(i[0]+i[1].split(\"\\t\")[1]+i[2].split(\"\\t\")[1]+\"\\n\")\n",
    "\n",
    "all_synonyms_translit.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synonyms = pd.read_csv(\"output/all synonyms translt.csv\", header=None, sep=\"\\t\")\n",
    "\n",
    "length = len(all_synonyms)\n",
    "\n",
    "for row in range(length):\n",
    "\theadword = all_synonyms.iloc[row, 0]\n",
    "\tsynonyms = str(all_synonyms.iloc[row, 1])\n",
    "\n",
    "\tsynonyms_list = synonyms.split()\n",
    "\tsynonyms_list = list(dict.fromkeys(synonyms_list))\n",
    "\n",
    "\twith open(f\"output/synonyms/{headword}\", \"wb\") as text_file:\n",
    "\t\tpickle.dump(synonyms_list, text_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
