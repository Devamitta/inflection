{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convert ods to csv\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from aksharamukha import transliterate\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in inflections table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflection_df = pd.read_excel('/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection-generator/declensions & conjugations.xlsx', sheet_name=\"declensions\", dtype=str)\n",
    "\n",
    "inflection_df = inflection_df.shift(periods=2)\n",
    "\n",
    "inflection_df.columns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"AB\", \"AC\", \"AD\", \"AE\", \"AF\", \"AG\", \"AH\", \"AI\", \"AJ\", \"AK\", \"AL\", \"AM\", \"AN\", \"AO\", \"AP\", \"AQ\", \"AR\", \"AS\", \"AT\", \"AU\", \"AV\", \"AW\", \"AX\", \"AY\", \"AZ\", \"BA\", \"BB\", \"BC\", \"BD\", \"BE\", \"BF\", \"BG\", \"BH\", \"BI\", \"BJ\", \"BK\", \"BL\", \"BM\", \"BN\", \"BO\", \"BP\", \"BQ\", \"BR\", \"BS\", \"BT\", \"BU\", \"BV\", \"BW\", \"BX\", \"BY\", \"BZ\", \"CA\", \"CB\", \"CC\", \"CD\", \"CE\", \"CF\", \"CG\", \"CH\", \"CI\", \"CJ\", \"CK\", \"CL\", \"CM\", \"CN\", \"CO\", \"CP\", \"CQ\", \"CR\", \"CS\", \"CT\", \"CU\", \"CV\", \"CW\", \"CX\", \"CY\", \"CZ\", \"DA\", \"DB\", \"DC\", \"DD\", \"DE\", \"DF\", \"DG\", \"DH\", \"DI\", \"DJ\", \"DK\"]\n",
    "inflection_df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_excel('/home/bhikkhu/Bodhirasa/Dropbox/dpd/inflection-generator/declensions & conjugations.xlsx', sheet_name=\"index\", dtype=str)\n",
    "index_df.fillna(\"\", inplace=True)\n",
    "# index_df[\"inflection name\"] = index_df[\"inflection name\"].str.replace(\" \", \"_\") #only needed if using as variable\n",
    "index_df_length = len(index_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate df's of each inflection pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for row in range(index_df_length):\n",
    "\tinflection_name = index_df.iloc[row,0]\n",
    "\tcell_range = index_df.iloc[row,1]\n",
    "\tlike = index_df.iloc[row,2]\n",
    "\tirreg = index_df.iloc[row,3]\n",
    "\t\n",
    "\tcol_range_1 = re.sub(\"(.+?)\\d*\\:.+\", \"\\\\1\", cell_range)\n",
    "\tcol_range_2 = re.sub(\".+\\:(.[A-Z]*)\\d*\", \"\\\\1\", cell_range)\n",
    "\trow_range_1 = int(re.sub(\".+?(\\d{1,3}):.+\", \"\\\\1\", cell_range))\n",
    "\trow_range_2 = int(re.sub(\".+:.+?(\\d{1,3})\", \"\\\\1\", cell_range))\n",
    "\n",
    "\t# print (f\"{inflection_name} || {cell_range} || {col_range_1}:{col_range_2} || {row_range_1}:{row_range_2}\")\n",
    "\n",
    "\tinflection_df_filtered = inflection_df.loc[row_range_1:row_range_2, col_range_1:col_range_2]\n",
    "\tinflection_df_filtered.Name =  f\"{inflection_name}\" #help! change the name to \"inflection name\" \n",
    "\n",
    "\tinflection_df_filtered.to_csv(f\"output/patterns/{inflection_name}.csv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate string of all inflections for each headword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpd_df = pd.read_csv(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd.csv\", sep=\"\\t\", dtype=str)\n",
    "# dpd_df.fillna(\"\", inplace=True)\n",
    "# dpd_df_length = len(dpd_df)\n",
    "\n",
    "# all_inflections = \"\"\n",
    "\n",
    "# for row in range(dpd_df_length): #dpd_df_length\n",
    "# \theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "# \theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "# \tstem = dpd_df.loc[row, \"Stem\"]\n",
    "# \tif stem == \"*\":\n",
    "# \t\tstem = \"\"\n",
    "# \tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "# \tpos = dpd_df.loc[row, \"POS\"]\n",
    "# \tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "# \tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\n",
    "# \tif row % 2000 == 0:\n",
    "# \t\tprint(f\"{row} {headword}\")\n",
    "\n",
    "# \tif pos != \"prefix\" and pos != \"cs\" and pos != \"suffix\" and pos != \"ve\" and pos != \"idiom\" and meaning != \"\" and metadata != \"yes\":\n",
    "# \t\t# print(f\"{headword=} {headword_clean=} {stem=} {pattern=} {pos=} {metadata=} {meaning=}\")\n",
    "\n",
    "# \t\tif stem == \"-\":\n",
    "# \t\t\tall_inflections += headword_clean + \" \"\n",
    "\n",
    "# \t\telif stem == \"!\":\n",
    "# \t\t\tall_inflections += headword_clean + \" \"\n",
    "\n",
    "# \t\telse:\n",
    "# \t\t\ttry:\n",
    "# \t\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", header=None)\n",
    "# \t\t\t\tdf.fillna(\"\", inplace=True)\n",
    "# \t\t\t\tdf_rows = df.shape[0]\n",
    "# \t\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "# \t\t\t\tfor rows in range(1, df_rows):\n",
    "# \t\t\t\t\tfor columns in range(1, df_columns, 2):\n",
    "# \t\t\t\t\t\tline = df.iloc[rows, columns]\n",
    "# \t\t\t\t\t\tif line == \"sg\" or line == \"pl\":\n",
    "# \t\t\t\t\t\t\tpass\n",
    "\n",
    "# \t\t\t\t\t\telse:\n",
    "# \t\t\t\t\t\t\tline = re.sub(r\"(.+)\", f\"{stem}\\\\1\", line)\n",
    "# \t\t\t\t\t\t\tsearch_string = re.compile(\"\\n\", re.M)\n",
    "# \t\t\t\t\t\t\treplace_string = \" \"\n",
    "# \t\t\t\t\t\t\tmatches = re.sub(search_string, replace_string, line)\n",
    "\n",
    "# \t\t\t\t\t\t\tall_inflections += matches + \" \"\n",
    "\t\t\t\t\t\t\n",
    "# \t\t\texcept:\n",
    "# \t\t\t\twith open(\"output/errors.txt\", \"a\") as error_log:\n",
    "# \t\t\t\t\terror_log.write(f\"error on: {headword}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dedupe and convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_inflections_list = all_inflections.split()\n",
    "# all_inflections_list = list(dict.fromkeys(all_inflections_list))\n",
    "# all_inflections_df = pd.DataFrame(all_inflections_list)\n",
    "# all_inflections_df.to_csv(\"output/all_inflections_df.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all inflection tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpd_df = pd.read_csv(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd-full.csv\", sep=\"\\t\", dtype=str)\n",
    "dpd_df.fillna(\"\", inplace=True) \n",
    "dpd_df_length = len(dpd_df)\n",
    "\n",
    "row = 0\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tif stem == \"*\":\n",
    "\t\tstem = \"\"\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tpos = dpd_df.loc[row, \"POS\"]\n",
    "\tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "\tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\n",
    "\t\n",
    "\n",
    "\tif row % 2000 == 0:\n",
    "\t\tprint(f\"{row} {headword}\")\n",
    "\t\n",
    "\twith open(f\"output/html/{headword}.html\", \"w\") as html_table:\n",
    "\n",
    "\t\tif stem == \"-\":\n",
    "\t\t\thtml_table.write(f\"<p><b>{headword_clean}</b> is indeclinable\")\n",
    "\n",
    "\t\telif stem == \"!\":\n",
    "\t\t\thtml_table.write(f\"<p>click on <b>{pattern}</b> for inflection table\")\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", header=None)\n",
    "\t\t\tdf.fillna(\"\", inplace=True)\n",
    "\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\tfor rows in range(1, df_rows):\n",
    "\t\t\t\tfor columns in range(1, df_columns, 2):\n",
    "\t\t\t\t\tcell = df.iloc[rows, columns]\n",
    "\n",
    "\t\t\t\t\tif cell == \"sg\" or cell == \"pl\":\n",
    "\t\t\t\t\t\tpass\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tcell = re.sub(r\"(.+)\", f\"<b>\\\\1</b>\", cell) # add bold\n",
    "\t\t\t\t\t\tcell = re.sub(r\"(.+)\", f\"{stem}\\\\1\", cell) # add stem\n",
    "\t\t\t\t\t\tcell = re.sub(r\"\\n\", \"<br>\", cell) # add line breaks\n",
    "\t\t\t\t\t\tdf.iloc[rows, columns] = cell\n",
    "\t\t\t\n",
    "\t\t\tfor columns in range(2, df_columns, 2):\t# drop extra rows\n",
    "\t\t\t\tdf.drop([columns], axis=1, inplace=True) \n",
    "\t\t\t\n",
    "\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\thtml_file = open (f\"output/html/{headword}.html\", \"w\")\n",
    "\t\t\tfor rows in range(df_rows):\n",
    "\t\t\t\tfor columns in range(df_columns):\n",
    "\t\t\t\t\tcell = df.iloc[rows, columns]\n",
    "\t\t\t\t\tif rows == 0 and columns == 0:\n",
    "\t\t\t\t\t\tcell = \"\"\"<table class = \"table2\"><tr><th></th>\"\"\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows == 0 and columns > 0:\n",
    "\t\t\t\t\t\tcell = \"<th>\" + cell + \"</th>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows > 0 and columns == 0:\n",
    "\t\t\t\t\t\tcell = \"<tr><th>\" + cell + \"</th>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows > 0 and columns > 0:\n",
    "\t\t\t\t\t\tcell = \"<td>\" + cell + \"</td>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\t\t\tif rows == df_rows and columns == df_columns:\n",
    "\t\t\t\t\t\tcell = \"<td>\" + cell + \"</td></table>\"\n",
    "\t\t\t\t\t\thtml_file.write(cell)\n",
    "\t\t\thtml_file.close()\n",
    "\n",
    "\n",
    "\t\t\t# for columns in range(df_columns): # add table html\n",
    "\t\t\t# \ttry:\n",
    "\t\t\t# \t\tif columns == 0:\n",
    "\t\t\t# \t\t\tdf.iloc[0, columns] = \"\"\"<table class = \"table2\"><tr><th>\"\"\" + df.iloc[0, columns] + \"</th>\"\n",
    "\t\t\t# \t\t\tdf.iloc[1:, columns] =  \"<tr><th>\" + df.loc[1:, columns] + \"</th>\"\n",
    "\t\t\t# \t\tif columns > 0:\n",
    "\t\t\t# \t\t\tdf.iloc[0, columns] = \"<th>\" + df.iloc[0, columns] + \"</th>\"\n",
    "\t\t\t# \t\t\tdf.iloc[1:, columns] =  \"<td>\" + df.iloc[1:, columns] + \"</td>\"\n",
    "\t\t\t# \t\tif columns == df_columns:\n",
    "\t\t\t# \t\t\tdf.iloc[df_rows, df_columns] =  df.iloc[df_rows, df_columns] + \"</table>\"\n",
    "\n",
    "\t\t\t# \texcept:\n",
    "\t\t\t# \t\twith open(\"output/table errors.txt\", \"a\") as table_error_log:\n",
    "\t\t\t# \t\t\ttable_error_log.write(f\"\")\n",
    "\t\t\t# \t\t\ttable_error_log.write(f\"{headword=}\\n{columns=}\\n\\n\")\n",
    "\t\n",
    "\t\t\t# df.to_csv(f\"output/html/{headword}.html\",  sep=\" \", index=None, header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpd_df = pd.read_csv(\"/home/bhikkhu/Bodhirasa/Dropbox/dpd/csvs/dpd-full.csv\", sep=\"\\t\", dtype=str)\n",
    "dpd_df.fillna(\"\", inplace=True)\n",
    "dpd_df_length = len(dpd_df)\n",
    "\n",
    "all_synonyms = open (\"output/all synonyms.csv\", \"w\")\n",
    "\n",
    "for row in range(dpd_df_length): #dpd_df_length\n",
    "\theadword = dpd_df.loc[row, \"Pāli1\"]\n",
    "\theadword_clean = re.sub(\" \\d*$\", \"\", headword)\n",
    "\tstem = dpd_df.loc[row, \"Stem\"]\n",
    "\tif stem == \"*\":\n",
    "\t\tstem = \"\"\n",
    "\tpattern = dpd_df.loc[row, \"Pattern\"]\n",
    "\tpos = dpd_df.loc[row, \"POS\"]\n",
    "\tmetadata = dpd_df.loc[row, \"Metadata\"]\n",
    "\tmeaning = dpd_df.loc[row, \"Meaning IN CONTEXT\"]\n",
    "\n",
    "\tsynonyms = \"\"\n",
    "\n",
    "\tif row % 1000 == 0:\n",
    "\t\tprint(f\"{row} {headword}\")\n",
    "\n",
    "\tif stem == \"-\":\n",
    "\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\telif stem == \"!\":\n",
    "\t\tsynonyms += headword_clean + \" \"\n",
    "\n",
    "\telse:\n",
    "\t\ttry:\n",
    "\t\t\tdf = pd.read_csv(f\"output/patterns/{pattern}.csv\", sep=\"\\t\", header=None)\n",
    "\t\t\tdf.fillna(\"\", inplace=True)\n",
    "\t\t\tdf_rows = df.shape[0]\n",
    "\t\t\tdf_columns = df.shape[1]\n",
    "\n",
    "\t\t\tfor rows in range(1, df_rows):\n",
    "\t\t\t\tfor columns in range(1, df_columns, 2):\n",
    "\t\t\t\t\tline = df.iloc[rows, columns]\n",
    "\t\t\t\t\tif line == \"sg\" or line == \"pl\":\n",
    "\t\t\t\t\t\tpass\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tline = re.sub(r\"(.+)\", f\"{stem}\\\\1\", line)\n",
    "\t\t\t\t\t\tsearch_string = re.compile(\"\\n\", re.M)\n",
    "\t\t\t\t\t\treplace_string = \" \"\n",
    "\t\t\t\t\t\tmatches = re.sub(search_string, replace_string, line)\n",
    "\n",
    "\t\t\t\t\t\tsynonyms += matches + \" \"\n",
    "\t\t\t\t\t\n",
    "\t\texcept:\n",
    "\t\t\twith open(\"output/errors.txt\", \"a\") as error_log:\n",
    "\t\t\t\terror_log.write(f\"error on: {headword}\\n\")\n",
    "\t\n",
    "\tall_synonyms.write(f\"{headword}\t{synonyms}\\n\")\n",
    "\n",
    "all_synonyms.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcribe synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synonyms = open(\"output/all synonyms.csv\", \"r\")\n",
    "all_synonyms_read = all_synonyms.read()\n",
    "all_synonyms.close()\n",
    "\n",
    "all_synonyms_translit = open(\"output/all synonyms translt.csv\", \"w\")\n",
    "\n",
    "sinhala = transliterate.process(\"IAST\",\"Sinhala\", all_synonyms_read, post_options =['SinhalaPali'])\n",
    "devanagari = transliterate.process(\"IAST\",\"Devanagari\",all_synonyms_read)\n",
    "\n",
    "roman = all_synonyms_read.split(\"\\n\")[:-1]\n",
    "sinhala = sinhala.split(\"\\n\")\n",
    "devanagari = devanagari.split(\"\\n\")\n",
    "\n",
    "for i in zip(roman, sinhala, devanagari):\t\n",
    "  all_synonyms_translit.write(i[0]+i[1].split(\"\\t\")[1]+i[2].split(\"\\t\")[1]+\"\\n\")\n",
    "\n",
    "all_synonyms_translit.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synonyms = pd.read_csv(\"output/all synonyms translt.csv\", header=None, sep=\"\\t\")\n",
    "\n",
    "length = len(all_synonyms)\n",
    "\n",
    "for row in range(length):\n",
    "\theadword = all_synonyms.iloc[row, 0]\n",
    "\tsynonyms = str(all_synonyms.iloc[row, 1])\n",
    "\n",
    "\tsynonyms_list = synonyms.split()\n",
    "\tsynonyms_list = list(dict.fromkeys(synonyms_list))\n",
    "\n",
    "\twith open(f\"output/synonyms/{headword}\", \"wb\") as text_file:\n",
    "\t\tpickle.dump(synonyms_list, text_file)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
